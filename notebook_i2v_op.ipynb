{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7dfd1f-d3ef-4ce1-99dd-046ccc067107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "os.environ[\"PATH\"] += \":/home/natsuki/miniconda3/envs/ada/bin\"\n",
    "device = \"cuda\"\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path\n",
    "import json\n",
    "#from multiprocessing.shared_memory import SharedMemory\n",
    "from IPython.display import display, clear_output\n",
    "from script_util import wrap_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e61920-0909-41f4-b9fb-d69875fccc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from script_util import wrap_G\n",
    "#cfg = \"00030-v4-mirror-auto4-gamma100-batch64-noaug-resumecustom/network-snapshot-011289.pkl\"\n",
    "cfg = \"00023-white_yc05_yw04-mirror-auto4-gamma10-noaug/network-snapshot-021800.pkl\"\n",
    "fm = Path(f\"/data/natsuki/training116/{cfg}\")\n",
    "G = wrap_G(fm, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbddb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.synth(G.map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf8e93-005d-4724-95ff-7f6919cd2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/natsuki/illustration2vec/tag_list.json\") as f:\n",
    "    tag = json.load(f)\n",
    "taginv = dict()\n",
    "for i, t in enumerate(tag):\n",
    "    taginv[t] = i\n",
    "\n",
    "with open(\"/home/natsuki/bizarre-pose-estimator/_data/danbooru/_filters/intently_combatively_rules.json\") as f:\n",
    "    rules = json.load(f) \n",
    "ruleinv = dict()\n",
    "for i, rule, in enumerate(rules):\n",
    "    t = rule[\"name\"]\n",
    "    ruleinv[t] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545a140-9bba-47d5-a92d-ec7195c2a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#, mmap_mode=\"r\"\n",
    "ws = np.load(\"/data/natsuki/fact_lib/ws.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb579e-aca4-4395-984a-411a8cd5eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ms\n",
    "%time biz = np.load(\"/data/natsuki/fact_lib/biz.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef99374-e3b3-44cb-b491-0968008bcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time preds = np.load(\"/data/natsuki/fact_lib/preds.npy\")\n",
    "#%time preds = np.load(arr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6c88e-63ce-4b84-998d-dd572e43dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import FastICA, PCA, IncrementalPCA, MiniBatchSparsePCA, SparsePCA, KernelPCA\n",
    "import itertools\n",
    "# Standard PCA\n",
    "class PCAEstimator():\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.solver = 'full'\n",
    "        self.transformer = PCA(n_components, svd_solver=self.solver)\n",
    "        self.batch_support = False\n",
    "\n",
    "    def get_param_str(self):\n",
    "        return f\"pca-{self.solver}_c{self.n_components}\"\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.transformer.fit(X)\n",
    "\n",
    "        # Save variance for later\n",
    "        self.total_var = X.var(axis=0).sum()\n",
    "\n",
    "        # Compute projected standard deviations\n",
    "        self.stdev = np.dot(self.transformer.components_, X.T).std(axis=1)\n",
    "\n",
    "        # Sort components based on explained variance\n",
    "        idx = np.argsort(self.stdev)[::-1]\n",
    "        self.stdev = self.stdev[idx]\n",
    "        self.transformer.components_[:] = self.transformer.components_[idx]\n",
    "\n",
    "        # Check orthogonality\n",
    "        dotps = [np.dot(*self.transformer.components_[[i, j]])\n",
    "            for (i, j) in itertools.combinations(range(self.n_components), 2)]\n",
    "        if not np.allclose(dotps, 0, atol=1e-4):\n",
    "            print('IPCA components not orghogonal, max dot', np.abs(dotps).max())\n",
    "\n",
    "        self.transformer.mean_ = X.mean(axis=0, keepdims=True)\n",
    "\n",
    "    def get_components(self):\n",
    "        var_ratio = self.stdev**2 / self.total_var\n",
    "        return self.transformer.components_, self.stdev, var_ratio\n",
    "pca = PCAEstimator(64)\n",
    "pca.fit(ws[:10**5])\n",
    "\n",
    "cp, std, var = pca.get_components()\n",
    "x = ws[:100].mean(axis=0)\n",
    "# 0rotate 1洋服ロング 2横回転 45ショートヘア 6暗髪、ツインテ 7つり目 8服ビキニ 9ロング 10首をかしげる 11 above bellow 13 ロングケモミミ\n",
    "\n",
    "F = lambda X: np.tanh(5*(X-.5))*.5+.5\n",
    "ps = [-i/10 for i in range(10)] + [-i/10 for i in range(10)][::-1] + [i/10 for i in range(10)] + [-i/10 for i in range(10)]\n",
    "for p in ps:\n",
    "    clear_output(wait=True)\n",
    "    i = 10\n",
    "    y = x + 2* p * cp[i] * std[i]\n",
    "    img = G.synth(torch.from_numpy(y[None,None,:][:,[0]*16,:]).to(device))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771eb37-76c7-406b-9263-1d1c450d7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "@lru_cache(maxsize=None)\n",
    "def search(index, thr=0.9):\n",
    "    return np.where(preds[:, index] > thr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428f3cb-5112-4caa-95b3-2b64391b937f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"予測率0.9以上のwベクトルの1000個の平均を記録する\"\"\"\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf\", 50)\n",
    "seedss = dict()\n",
    "imgs = dict()\n",
    "wms = dict()\n",
    "missing = list()\n",
    "for index, query in enumerate(tag):\n",
    "    clear_output(wait=True)\n",
    "    wm = 0\n",
    "    searched = search(index, 0.9)\n",
    "    seedss[query] = searched\n",
    "    cnt = len(searched)\n",
    "    if cnt == 0:\n",
    "        missing.append(query)\n",
    "        continue\n",
    "    wm = torch.from_numpy(ws[searched[:1000]].mean(axis=0)[None,None,:][:,[0]*16,:]).to(device)\n",
    "    img = G.synth(wm)\n",
    "    ImageDraw.Draw(img).text((0,0), f\"{query}\\n{index}\\n{cnt}\", (0,0,0), font)\n",
    "    wms[query] = wm\n",
    "    imgs[query] = img\n",
    "    display(img)\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ae126-4ef5-49ca-af09-34e68ec16d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(tag):\n",
    "    if \" ears\" in t:\n",
    "        print(t, len(search(taginv[t], 0.9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a3efa-bdd8-4843-950c-00ad94edc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffec34-c741-4c3d-ba05-706e5a6a3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"wolf ears\" #334\n",
    "t = \"fox ears\" #376\n",
    "t = \"cat ears\" #89\n",
    "t = \"animal ears\" #32\n",
    "t = \"1boy\" #24\n",
    "t = \"glasses\" #57\n",
    "t = \"hair over one eye\" #281\n",
    "t = \"patchouli knowledge\" #520\n",
    "i = taginv[t]\n",
    "#print(i, t)\n",
    "#searched = search(i, 0.9)\n",
    "\n",
    "from nokogiri.defaultdotdict import defaultdotdict\n",
    "score = defaultdotdict(float)\n",
    "for i, t in enumerate(tqdm(tag)):\n",
    "    N = 1000\n",
    "    searched = preds[:,i].argsort()[-N:]\n",
    "    score.mean = preds[:,i][searched].mean()\n",
    "    score.std = preds[:,i][searched].std()\n",
    "    score.max = preds[:,i][searched].max()\n",
    "    score.min = preds[:,i][searched].min()\n",
    "    txt = \" \".join(f\"{k}={v:0.4f}\" for k, v in score.items())\n",
    "    with open(f\"/data/natsuki/fact_lib/i2v_txt/{i}.txt\", \"w\") as f:\n",
    "        f.write(txt)\n",
    "    wm_np = ws[searched].mean(axis=0)\n",
    "    wm = torch.from_numpy(wm_np[None,None,:][:,[0]*16,:]).to(device)\n",
    "    np.save(f\"/data/natsuki/fact_lib/i2v_wm/{i}.npy\", wm_np)\n",
    "    img = G.synth(wm)\n",
    "    img.save(f\"/data/natsuki/fact_lib/i2v_img/{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068a38f-f4d6-44cf-b7bc-339b904b8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[\"1boy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5187e-0309-4d92-96c6-9dc4322e17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[\"patchouli knowledge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f7ea2-d6fd-42d0-ba2b-e317192772d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = lambda X: np.tanh(5*(X-.5))*.5+.5\n",
    "ps = [1/i for i in range(1, 10+1)]\n",
    "ps = ps[::-1] + [1]*10 +ps\n",
    "ps = [p for p in ps]\n",
    "arrs = list()\n",
    "for p in ps:\n",
    "    clear_output(wait=True)\n",
    "    #img, arr = G.synth(wms[\"izayoi sakuya\"] + p*(wms[\"animal ears\"]-wms[\"safe\"]), retarr=True)\n",
    "    #img, arr = G.synth(wms[\"patchouli knowledge\"] + p*(wms[\"glasses\"]-wms[\"safe\"]), retarr=True)\n",
    "    #img, arr = G.synth(wms[\"hatsune miku\"] + p*(wms[\"animal ears\"]-wms[\"safe\"]), retarr=True)\n",
    "    img, arr = G.synth(wms[\"izayoi sakuya\"] + p*(wms[\"closed eyes\"]-wms[\"safe\"]), retarr=True)\n",
    "    arrs.append(arr)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e84b1-73ca-4be7-9dec-a94ab6419bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from subprocess import check_output\n",
    "dname = \"megane.gif\"\n",
    "imageio.mimsave(dname, arrs, fps=10)\n",
    "print(check_output(f\"du -sh {dname}\", shell=True).decode(), end=\"\")\n",
    "print(check_output(f\"mogrify -layers 'optimize' -fuzz 3% -loop 0 {dname}\", shell=True).decode(), end=\"\")\n",
    "print(check_output(f\"du -sh {dname}\", shell=True).decode(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd1cb5-300e-4e7e-b67d-fe45d3995212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs.values:\n",
    "    clear_output(wait=True)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c93af-d28c-4625-8c10-9d7de6e074a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipyplot\n",
    "ipyplot.plot_images(list(imgs.values())[700:], max_images=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psp_env",
   "language": "python",
   "name": "psp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
