{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from ipynb.fs.full.notebook_viewer import Viewer, Manager, load_wimage\n",
    "from script_util import root, fname2id, id2fname, split_dump, search_dump, Filter, prepare, tqdm_load, id2, cmap, rcParams\n",
    "import pickle\n",
    "from pickle import Unpickler\n",
    "from pprint import pprint\n",
    "from dotdict import dotdict\n",
    "from functools import reduce\n",
    "\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import imagesize\n",
    "from math import atan2, degrees\n",
    "import plotly.express as px\n",
    "from itertools import combinations\n",
    "\n",
    "plt.rcParams.update(rcParams)\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_ori =  set((root/\"danbooru2020/dump_readable_ori/0\").read_text().strip().split())\n",
    "readable_originalwhite =  set((root/\"danbooru2020/dump_readable_originalwhite/0\").read_text().strip().split())\n",
    "missing2x = {\"4005075\",\"685111\",\"3554125\",\"3004206\",\"1783239\",\"528288\",\"1717363\",\"4268380\",\"750472\",\"1106509\",\"2072514\",\"2072517\",\"3185545\",\"4039613\",\"3051636\",\"4089762\",\"800782\",\"2515799\",\"1195810\",\"4260855\"}\n",
    "missingsolov2 = {'1084454','2334893','2829693','2832773','2945896','3608576','3657998','3701002','3822349','4054580'}\n",
    "missinggrav = {'3634238','3634244'}\n",
    "\n",
    "\n",
    "fire_eggs = dict()\n",
    "for k in \"duplicates is_deleted no_humans not-image photo text_only_page\".split():\n",
    "    fire_eggs[k] = set((root/f\"danbooru2020/Danbooru2019/reduce/{k}.txt\").read_text().strip().split())\n",
    "    \n",
    "ge512 =  set((root/\"danbooru2020/ge512.ids\").read_text().strip().split())\n",
    "ge1024 =  set((root/\"danbooru2020/ge1024.ids\").read_text().strip().split())\n",
    "\n",
    "i = 2\n",
    "if not \"ids\" in globals():\n",
    "    ids = tqdm_load(root/f\"danbooru2020/{i}_id.pkl\")\n",
    "if not \"tags\" in globals():\n",
    "    tags = tqdm_load(root/f\"danbooru2020/{i}_tag.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def t(s):\n",
    "    if \"|\" in s:\n",
    "        retval = reduce(set.__or__, map(tags.get, s.split(\"|\")))\n",
    "    else:\n",
    "        retval = reduce(set.__and__, map(tags.get, s.split(\"&\")))\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_one = set((root/\"danbooru2020/dump_face_one/0\").read_text().strip().split())\n",
    "instance_one = set((root/\"danbooru2020/dump_instance_one/0\").read_text().strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = Filter()\n",
    "fl[\"faceinstance\"] = (face_one & instance_one) - {'3634238','3634244'}\n",
    "fl[\"censored\"]     = fl[-1]-tags[\"censored\"]\n",
    "fl[\"safe\"]         = {_id for _id in fl[\"censored\"] if ids[_id][\"rating\"] == \"s\"}\n",
    "exc1 = t('|'.join([\n",
    "    \"zoom_layer\",\n",
    "    \"back|ass|from_behind|from_above|bent_over|standing_split\",\n",
    "    \"car|bicycle|translation_request|mystery_skulls\",\n",
    "    \"fox_tail|otter_costume|sonic_the_hedgehog\",\n",
    "    \"floating_head|cyclops|fat|electric_guitar\",\n",
    "]))|reduce(set.__or__, fire_eggs.values())\n",
    "fl[\"out\"]          = fl[\"safe\"]-exc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samesize = defaultdict(list)\n",
    "for _id in tqdm(fl[\"out\"]):\n",
    "    fname = id2.originalwhite(_id)\n",
    "#    a = tuple(map(int, map(ids[_id].get, ['image_width', 'image_height'])))\n",
    "    b = imagesize.get(fname)\n",
    "#    assert a == b\n",
    "    samesize[b].append(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for k, v in samesize.items():\n",
    "    s += len(v)*(len(v)-1)//2\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ok: RGB空間でのMSE\n",
    "この時点ではtagsから画像サイズを取っているため実際の画像サイズと不整合がある場合は65536となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dump([\"\\t\".join(v) for v in samesize.values()        len(v) > 10 ], \"samesize\"  , N= 1)\n",
    "split_dump([\"\\t\".join(v) for v in samesize.values() if 1 < len(v) <= 10], \"samesize10\", N=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_dump(\n",
    "    [\"\\t\".join(c) for c in combinations((root/\"danbooru2020/dump_samesize/10\").read_text().strip().split(), 2)] + \n",
    "    [\"\\t\".join(c) for c in combinations((root/\"danbooru2020/dump_samesize/35\").read_text().strip().split(), 2)]\n",
    ",\"samesize100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fnames = [id2fname(f\"{fname2id(f1)}_{fname2id(f2)}\", prefix=\"issame\", bucket=lambda _:\".\") for m,f1,f2 in ok if m < 30]\n",
    "split_dump([f\"-resize 512x512 -background white -gravity center -extent 512x512 {fname}\" for fname in fnames], \"samesize_resize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list((root/\"danbooru2020/samesize\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB空間でのMSE\n",
    "THR = float(\"inf\")\n",
    "ok = list()\n",
    "for i, fname in enumerate(tqdm(results)):\n",
    "    with fname.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            m, f1, f2 = line.strip().split()\n",
    "            if not fname2id(f1) in fl[\"out\"]:\n",
    "                continue\n",
    "            if not fname2id(f2) in fl[\"out\"]:\n",
    "                continue\n",
    "            m = float(m)\n",
    "            f12name = id2fname(f\"{fname2id(f1)}_{fname2id(f2)}\", prefix=\"issame\", bucket=lambda _:\".\")\n",
    "            if THR < m:\n",
    "                break # find ./ -type f|grep -v \"_\"| xargs -i sort -n {} -o {} \n",
    "            else:\n",
    "                ok.append((m, f12name))\n",
    "ok.sort()\n",
    "print(len(ok), ok[0][0], ok[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ok_fix: インスタンスをマスクしてRGB空間でMSE\n",
    "実際のファイルから画像サイズを取るようにした。人物の差分に注目するため背景のピクセルを計算から除外することにした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_fix = [id2fname(f\"{fname2id(f1)}_{fname2id(f2)}\", prefix=\"issame\", bucket=lambda _:\".\") for m,f1,f2 in ok_fix if -1 < m <= 221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def append_option(dname):\n",
    "    _id = fname2id(dname)\n",
    "    f1name = id2.originalwhite(_id.split(\"_\")[0])\n",
    "    f2name = id2.originalwhite(_id.split(\"_\")[1])\n",
    "    return f\"convert +append {f1name} {f2name} -resize 256x384 -background white -gravity center -extent 256x384 {dname}\"\n",
    "(root/\"danbooru2020/issame_fix\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_dump(list(map(append_option, fnames_fix)), \"option_issame_fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fix = list((root/\"danbooru2020/samesize_fix\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB空間でインスタンスをマスクしてMSE\n",
    "#THR_FIX = 221\n",
    "THR_FIX = float(\"inf\")\n",
    "ok_fix = list()\n",
    "for i, fname in enumerate(tqdm(results_fix)):\n",
    "    with fname.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            m, f1, f2 = line.strip().split()\n",
    "            if not fname2id(f1) in fl[\"out\"]:\n",
    "                continue\n",
    "            if not fname2id(f2) in fl[\"out\"]:\n",
    "                continue\n",
    "            m = float(m)\n",
    "            f12name = id2fname(f\"{fname2id(f1)}_{fname2id(f2)}\", prefix=\"issame\", bucket=lambda _:\".\")\n",
    "            if THR_FIX < m:\n",
    "                break # find ./ -type f|grep -v \"_\"| xargs -i sort -n {} -o {} \n",
    "            else:\n",
    "                ok_fix.append((m, f12name))\n",
    "ok_fix.sort()\n",
    "print(len(ok_fix), ok_fix[0][0], ok_fix[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram([a[0] for a in ok_fix])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer_fix.bag |= {id2fname(f\"{fname2id(f1)}_{fname2id(f2)}\", prefix=\"issame\", bucket=lambda _:\".\") for m,f1,f2 in ok_fix if -1 < m <= 70}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_fix = Viewer(fl[\"0\"], key = \"nosort\", name =\"reduce_duplicates_fix\", N=13*8-1)\n",
    "viewer_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [ for m,f1,f2 in ok if m < 30]\n",
    "print(len(fnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ok_masklab: インスタンスをマスクしてLab空間上でMSE\n",
    "fl[\"faceinstance\"]は巨大すぎて見切れないので、fl[\"out\"]に対象を絞った。RGB空間よりLab空間上での距離の方が人間の色覚に即した距離が出るため、補助的に採用した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_masklab = list((root/\"danbooru2020/masklab\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_masklab_all = list()\n",
    "for i, fname in enumerate(tqdm(results_masklab)):\n",
    "    with fname.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            m, f12name = line.strip().split()\n",
    "            fid1, fid2 = fname2id(f12name).split(\"_\")\n",
    "            if not fid1 in fl[\"out\"]:\n",
    "                continue\n",
    "            if not fid2 in fl[\"out\"]:\n",
    "                continue\n",
    "            m = float(m)\n",
    "            ok_masklab_all.append((m, f12name))\n",
    "ok_masklab_all.sort()\n",
    "print(len(ok_masklab_all), ok_masklab_all[0][0], ok_masklab_all[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Manager([f12name for m,f12name in ok_fix], key = \"nosort\", name =\"reduce_duplicates_fix_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = Manager.MANAGED[\"reduce_duplicates_fix_out\"].bag\n",
    "bin = 10\n",
    "f=int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt = [0]*(1+f(max(ok_fix)[0])//bin)\n",
    "yes = [0]*len(cnt)\n",
    "for m, f12name in tqdm(ok_fix):\n",
    "    cnt[f(m)//bin] += 1\n",
    "    if f12name in bag:\n",
    "        yes[f(m)//bin] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [100*y/(c+eps) for c, y in zip(cnt, yes)]\n",
    "data2 = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "X = [bin*i for i in range(len(data1))]\n",
    "ax1.set_ylabel('見つかった重複・差分画像の割合', color=cmap(3)) \n",
    "ax1.plot(X, data1, color=cmap(3))\n",
    "ax1.tick_params(axis='y', labelcolor=cmap(3))\n",
    "\n",
    "ax2.set_ylabel('このMSEの値を取る2枚の画像組の件数', color=cmap(2))\n",
    "ax2.plot(X, data2, color=cmap(2))\n",
    "ax2.tick_params(axis='y', labelcolor=cmap(2))\n",
    "\n",
    "ax1.set_xlabel('MSE（人の写った領域のみに注目して計算）')\n",
    "plt.title(\"サイズの等しい二枚の画像を目視で重複除去した結果\")\n",
    "\n",
    "fig.tight_layout()# otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada2",
   "language": "python",
   "name": "ada2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
