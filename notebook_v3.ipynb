{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import ipynb.fs.full.notebook_viewer\n",
    "reload(ipynb.fs.full.notebook_viewer)\n",
    "from ipynb.fs.full.notebook_viewer import Viewer, root, bucket, fname2id, id2fname, split_dump, Filter\n",
    "import pickle\n",
    "from pickle import Unpickler\n",
    "from pprint import pprint\n",
    "from dotdict import dotdict\n",
    "from functools import reduce\n",
    "\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from vivid.utils import timer\n",
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TQDMBytesReader(object):\n",
    "    def __init__(self, fd, **kwargs):\n",
    "        self.fd = fd\n",
    "        self.tqdm = tqdm(**kwargs)\n",
    "    def read(self, size=-1):\n",
    "        bytes = self.fd.read(size)\n",
    "        self.tqdm.update(len(bytes))\n",
    "        return bytes\n",
    "    def readline(self):\n",
    "        bytes = self.fd.readline()\n",
    "        self.tqdm.update(len(bytes))\n",
    "        return bytes\n",
    "    def __enter__(self):\n",
    "        self.tqdm.__enter__()\n",
    "        return self\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        return self.tqdm.__exit__(*args, **kwargs)\n",
    "def tqdm_load(fname):\n",
    "    with open(fname, \"rb\") as fd:\n",
    "         total = Path(fname).stat().st_size\n",
    "         with TQDMBytesReader(fd, total=total) as pbfd:\n",
    "             up = Unpickler(pbfd)\n",
    "             obj = up.load()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_ori =  set((root/\"danbooru2020/dump_readable_ori/0\").read_text().strip().split())\n",
    "missing2x = {\"4005075\",\"685111\",\"3554125\",\"3004206\",\"1783239\",\"528288\",\"1717363\",\"4268380\",\"750472\",\"1106509\",\"2072514\",\"2072517\",\"3185545\",\"4039613\",\"3051636\",\"4089762\",\"800782\",\"2515799\",\"1195810\",\"4260855\"}\n",
    "\n",
    "fire_eggs = dict()\n",
    "for k in \"duplicates is_deleted no_humans not-image photo text_only_page\".split():\n",
    "    fire_eggs[k] = set((root/f\"danbooru2020/Danbooru2019/reduce/{k}.txt\").read_text().strip().split())\n",
    "    \n",
    "ge512 =  set((root/\"danbooru2020/ge512.ids\").read_text().strip().split())\n",
    "ge1024 =  set((root/\"danbooru2020/ge1024.ids\").read_text().strip().split())\n",
    "\n",
    "i = 2\n",
    "if not \"ids\" in globals():\n",
    "    with timer(prefix=\"read_id_pkl\"): # 311[s]\n",
    "        ids = tqdm_load(root/f\"danbooru2020/{i}_id.pkl\")\n",
    "if not \"tags\" in globals():\n",
    "    with timer(prefix=\"read_tag_pkl\"): # 58[s]\n",
    "        tags = tqdm_load(root/f\"danbooru2020/{i}_tag.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def t(s):\n",
    "    if \"|\" in s:\n",
    "        retval = reduce(set.__or__, map(tags.get, s.split(\"|\")))\n",
    "    else:\n",
    "        retval = reduce(set.__and__, map(tags.get, s.split(\"&\")))\n",
    "    return retval\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_json(fname):\n",
    "    fname = str(fname)\n",
    "    retval = dotdict({k.replace(\"detection_\", \"\").replace(\"bbox_\", \"\").replace(\"class_\", \"\"): np.array(v) for k, v in json.loads(Path(fname).read_text()).items()})\n",
    "    retval[\"fname\"] = fname\n",
    "    retval[\"id\"] = fname2id(fname)\n",
    "    return retval\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_pkl(fname):\n",
    "    fname = str(fname)\n",
    "    with open(fname, \"rb\") as f:\n",
    "        retval = dotdict(pickle.load(f))\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2original(_id):\n",
    "    return id2fname(_id, prefix=\"original\", ext=lambda _id: ids[_id][\"file_ext\"])\n",
    "\n",
    "def id2original2x(_id):\n",
    "    if _id in tags[\"highres\"]:\n",
    "        return id2original(_id)\n",
    "    return id2fname(_id, prefix=\"original2x\", ext=lambda _: \"png\")\n",
    "\n",
    "def id2original2xwhite(_id):\n",
    "    if _id in tags[\"highres\"]:\n",
    "        return id2fname(_id, prefix=\"originalwhite\", ext=lambda _: \"png\")\n",
    "    return id2fname(_id, prefix=\"original2xwhite\", ext=lambda _: \"png\")\n",
    "\n",
    "def id2json(_id):\n",
    "    return id2fname(_id, prefix=\"solo_json\", bucket=lambda _: \".\", ext=lambda _: \"json\")\n",
    "\n",
    "def id2pkl(_id):\n",
    "    return id2fname(_id, prefix=\"yaas/solov2out\", ext=lambda _: \"pkl\")\n",
    "\n",
    "def grouping(fnames, load=load_json, f=lambda x: np.where(x.label == 1)[0]):\n",
    "    r = dotdict()\n",
    "    r.fnames = tuple(map(str, fnames))\n",
    "    r.zero = set()\n",
    "    r.one = set()\n",
    "    r.multi = set()\n",
    "    pbar =  tqdm(r.fnames)\n",
    "    for i, fname in enumerate(pbar):\n",
    "        _id = fname2id(fname)\n",
    "        x = load(fname)\n",
    "        r[_id] = x\n",
    "        fx = f(x)\n",
    "        if len(fx) == 0:\n",
    "            r.zero.add(_id)\n",
    "        elif len(fx) == 1:\n",
    "            r.one.add(_id)\n",
    "        else:\n",
    "            r.multi.add(_id)\n",
    "        if i+1 == len(r.fnames):\n",
    "            pbar.set_description(str(len(r.one)/(i+1)*100)[:2]+\"%\")\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = t(\"1girl|solo|1boy\")-t(\"1girl&1boy\")-t(\"2boys|2girls|3boys|3girls|4boys|4girls|5boys|5girls|6+boys|6+girls|multiple_boys|multiple_girls|multiple_views|variations\")\n",
    "bg = t(\"white_background|transparent_background\")\n",
    "#bg = t(\"white_background|transparent_background|simple_background\")-t(\"black_background|dark_background\")\n",
    "exc0 = t('|'.join([\n",
    "    \"no_humans|arachne|pokemon_(creature)|octoling|monster_girl|isabelle_(animal_crossing)|animal_nose|animal_hug\",\n",
    "    \"robot|cyborg|mecha_musume|machinery|doll_joints|crewmate_(among_us)|kamen_rider_faiz|olimar\",\n",
    "    \"red_skin|blue_skin|purple_skin|wrinkled_skin|green_skin|two-tone_skin\",\n",
    "    \"monochrome|lineart|text_only_page|photo-referenced|3d|unconventional_media|comic\",\n",
    "    \"photo_(medium)|reference_photo_inset|reference_photo|photorealistic\",\n",
    "    \"full_armor|weapon|chibi|cannon|mask|eyepatch\",\n",
    "]))\n",
    "exc1 = t('|'.join([\n",
    "    \"zoom_layer\",\n",
    "    \"back|ass|from_behind|from_above|bent_over|dutch_angle|standing_split\",\n",
    "    \"car|bicycle\",\n",
    "    \"translation_request\",\n",
    "    \"fox_tail\",\n",
    "    \"otter_costume\",\n",
    "    \"sonic_the_hedgehog\",\n",
    "    \"mystery_skulls\",\n",
    "    \"floating_head\",\n",
    "]))|reduce(set.__or__, fire_eggs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = Filter()\n",
    "fl[\"solo\"]         = solo&readable_ori - missing2x\n",
    "fl[\"exc0\"]         = fl[-1]-exc0\n",
    "fl[\"standing\"]     = fl[-1]&tags[\"standing\"]\n",
    "fl[\"ge512\"]        = fl[-1]&ge512\n",
    "face     = grouping(map(id2json, fl[\"ge512\"]), load=load_json, f=lambda x: np.where(x.label == 1)[0])\n",
    "instance = grouping(map(id2pkl,  fl[\"ge512\"]), load=load_pkl,  f=lambda x: x.pred_classes)\n",
    "fl[\"faceinstance\"] = fl[-1]&face.one&instance.one\n",
    "fl[\"bg\"]           = fl[-1]&bg\n",
    "fl[\"censored\"]     = fl[-1]-tags[\"censored\"]\n",
    "fl[\"safe\"]         = {_id for _id in fl[\"censored\"] if ids[_id][\"rating\"] == \"s\"}\n",
    "fl[\"questionable\"] = {_id for _id in fl[\"censored\"] if ids[_id][\"rating\"] == \"q\"}\n",
    "fl[\"explicit\"]     = {_id for _id in fl[\"censored\"] if ids[_id][\"rating\"] == \"e\"}\n",
    "fl[\"full_body\"]    = fl[\"safe\"]&tags[\"full_body\"]\n",
    "fl[\"out\"]          = fl[\"safe\"]-exc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Viewer(map(id2original2x, fl[\"out\"]), name=\"out_score\", N=11, key = lambda _id: -int(ids[_id][\"score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_option(_id, dname, xc=0.5, yc=0.28, yw=0.235, size=512):\n",
    "    fname = id2original(_id)\n",
    "    j = load_json(id2json(_id))\n",
    "    src = dotdict()\n",
    "    dst = dotdict()\n",
    "    src.X, src.Y = imagesize.get(fname)\n",
    "    i = np.where(j.label==1)[0][0]\n",
    "    src.Xmin = src.X*j.xmin[i]\n",
    "    src.Xmax = src.X*j.xmax[i]\n",
    "    src.Ymin = src.Y*j.ymin[i]\n",
    "    src.Ymax = src.Y*j.ymax[i]\n",
    "    src.Ywid = src.Ymax-src.Ymin\n",
    "    src.Xcen = (src.Xmax+src.Xmin)/2\n",
    "    src.Ycen = (src.Ymax+src.Ymin)/2\n",
    "    dst = dotdict()\n",
    "    dst.Xcen = size*xc\n",
    "    dst.Ycen = size*yc\n",
    "    dst.Ywid = size*yw\n",
    "    z = dst.Ywid/src.Ywid\n",
    "    option = [\n",
    "        \"-background\", \"white\",\n",
    "        \"-resize\", f\"{round(100*z)}%\",\n",
    "        \"-crop\", f\"{size}x{size}+{round(z*src.Xcen-dst.Xcen)}+{round(z*src.Ycen-dst.Ycen)}!\",\n",
    "        \"-flatten\",\n",
    "        \"-strip\",\n",
    "        \"-quality\", \"100\",\n",
    "        f\"{fname}\",\n",
    "        f\"PNG24:{dname}\",\n",
    "    ]\n",
    "    return option\n",
    "options = list()\n",
    "for _id in tqdm(out_score):\n",
    "    option = \" \".join(convert_option(_id, id2fname(_id, prefix=\"v3\")))\n",
    "    options.append(option)\n",
    "split_dump(options, \"option_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = list()\n",
    "for fname in tqdm(list((root/\"danbooru2020/v3\").glob(\"**/*.png\"))):\n",
    "    sample.append( np.array(Image.open(fname)) )\n",
    "Image.fromarray(np.mean(sample, axis=0).astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_option(fname, dname):\n",
    "    return f\"/home/natsuki/waifu2x/waifu2x.lua -m scale -i {fname} -o {dname}\".split()\n",
    "options = list()\n",
    "for _id in tqdm(list((fl[\"ge512\"]-tags[\"highres\"])|face.zero)):\n",
    "    option = \" \".join(th_option(_id, id2fname(id2original(_id), prefix=\"original2x\")))\n",
    "    options.append(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dump(options, \"option_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = list()\n",
    "for fname in tqdm(list(map(str, (root/\"getchu_s5\").glob(\"*\")))):\n",
    "    dname = fname.replace(\"getchu_s5\", \"getchu_s5_2x\")\n",
    "    option = \" \".join(th_option(fname, dname))\n",
    "    options.append(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dump(options, \"option_getchu_s5_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 75+1):\n",
    "    for line in (root/f\"danbooru2020/dump_option_2x/{i}\").read_text().strip().split(\"\\n\"):\n",
    "        fname = line.split()[-3]\n",
    "        _id = fname2id(fname)\n",
    "        tname = f\"/tmp{_id}.png\"\n",
    "        if Path(dname).is_file():\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"convert {fname} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = list(map(id2pkl, fl[\"ge512\"]))\n",
    "g = grouping(fnames, load=load_pkl, f=lambda x: x.pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _id in instance.one:\n",
    "    img = Image.fromarray((255*instance[_id].pred_masks[0])).convert(\"1\")\n",
    "    break\n",
    "img\n",
    "#h, w = map(round, np.array(np.where(p.pred_masks[0])).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image.fromarray((255*p.pred_masks[0]).astype(\"uint8\")).convert(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg = fl[\"faceinstance\"]-t(\"simple_background\")-white-exc1\n",
    "print(len(nbg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options_convert = list()\n",
    "options_mogrify = list()\n",
    "for i, _id in enumerate(tqdm(instance.one)):\n",
    "    srcname = id2original2xwhite(_id)\n",
    "#    src = np.array(Image.open(fname))\n",
    "#    str(root/f\"danbooru2020/yaas/solov2out/{bucket(_id)}/{_id}.png\")\n",
    "#    str(root/f\"danbooru2020/original2xwhitesolov2/{bucket(_id)}/{_id}.png\")\n",
    "    maskname  = id2fname(_id, prefix=\"yaas/solov2out\", ext= lambda _:\"png\")\n",
    "    dstname = id2fname(_id, prefix=\"original2xwhitesolov2\", ext=lambda _:\"png\")\n",
    "    options_convert.append( f\"{srcname} {maskname} -compose CopyOpacity -composite {dstname}\" )\n",
    "    options_mogrify.append( f\"-background white -flatten PNG24:{dstname}\")\n",
    "#    mask = instance[_id].pred_masks[0]\n",
    "#    H, W = mask.shape\n",
    "#    arr = 255*np.ones((H, W, 4), dtype=\"uint8\")\n",
    "#    arr[:,:,3] = 255*mask\n",
    "#    img = Image.fromarray(arr)\n",
    "#    img = Image.fromarray((255*mask).astype(\"uint8\")).convert(\"1\")\n",
    "#    img.save(dname)\n",
    "#    if i == 1000:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dump(options_convert, \"option_original2xwhitesolov2_convert\")\n",
    "split_dump(options_mogrify, \"option_original2xwhitesolov2_mogrify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_id = \"2832570\"\n",
    "mask = instance[_id].pred_masks[0]\n",
    "#H, W = mask.shape\n",
    "#arr = 255*np.ones((H, W, 4), dtype=\"uint8\")\n",
    "#arr[:,:,3] = 255*mask\n",
    "#\n",
    "img = Image.fromarray((255*mask).astype(\"uint8\")).convert(\"1\")\n",
    "#img = Image.fromarray(arr)\n",
    "img.save(\"/tmp/1.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"convert {fname} {dname} -compose CopyOpacity -composite /tmp/out.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viewer(map(id2fname, instance.multi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
