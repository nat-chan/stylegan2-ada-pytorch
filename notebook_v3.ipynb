{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import ipynb.fs.full.notebook_viewer\n",
    "reload(ipynb.fs.full.notebook_viewer)\n",
    "from ipynb.fs.full.notebook_viewer import Viewer, root, bucket, fname2id, id2fname, split_dump\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from dotdict import dotdict\n",
    "from functools import reduce\n",
    "\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from vivid.utils import timer\n",
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = set(Path(root/\"danbooru2019/512px.dat\").read_text().strip().split())\n",
    "safe =  set((root/\"danbooru2020/512px.dat\").read_text().strip().split())\n",
    "\n",
    "readable_ori =  set((root/\"danbooru2020/dump_readable_ori/0\").read_text().strip().split())\n",
    "\n",
    "fire_eggs = dict()\n",
    "for k in \"duplicates is_deleted no_humans not-image photo text_only_page\".split():\n",
    "    fire_eggs[k] = set((root/f\"danbooru2020/Danbooru2019/reduce/{k}.txt\").read_text().strip().split())\n",
    "    \n",
    "ge512 =  set((root/\"danbooru2020/ge512.ids\").read_text().strip().split())\n",
    "ge1024 =  set((root/\"danbooru2020/ge1024.ids\").read_text().strip().split())\n",
    "\n",
    "i = 2\n",
    "if not \"ids\" in globals():\n",
    "    with timer(prefix=\"read_id_pkl\"): # 311[s]\n",
    "        with open((root/f\"danbooru2020/{i}_id.pkl\"), \"rb\") as f:\n",
    "            ids = pickle.load(f)\n",
    "if not \"tags\" in globals():\n",
    "    with timer(prefix=\"read_tag_pkl\"): # 58[s]\n",
    "        with open((root/f\"danbooru2020/{i}_tag.pkl\"), \"rb\") as f:\n",
    "            tags = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def t(s):\n",
    "    if \"|\" in s:\n",
    "        retval = reduce(set.__or__, map(tags.get, s.split(\"|\")))\n",
    "    else:\n",
    "        retval = reduce(set.__and__, map(tags.get, s.split(\"&\")))\n",
    "    return retval\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_json(fname):\n",
    "    fname = str(fname)\n",
    "    retval = dotdict({k.replace(\"detection_\", \"\").replace(\"bbox_\", \"\").replace(\"class_\", \"\"): np.array(v) for k, v in json.loads(Path(fname).read_text()).items()})\n",
    "    retval[\"fname\"] = fname\n",
    "    retval[\"id\"] = fname2id(fname)\n",
    "    return retval\n",
    "\n",
    "def id2original(_id):\n",
    "    return id2fname(_id, prefix=\"original\", ext=lambda _id: ids[_id][\"file_ext\"])\n",
    "\n",
    "def id2json(_id):\n",
    "    return id2fname(_id, prefix=\"solo_json\", bucket=lambda _: \".\", ext=lambda _: \"json\")\n",
    "\n",
    "def groupj(jfnames):\n",
    "    r = dotdict()\n",
    "    r.jfnames = tuple(map(str, jfnames))\n",
    "    r.zero = set()\n",
    "    r.one = set()\n",
    "    r.multi = set()\n",
    "    for fname in tqdm(r.jfnames):\n",
    "        j = load_json(fname)\n",
    "        r[j.id] = j\n",
    "        w = np.where(j.label == 1)[0]\n",
    "        if len(w) == 0:\n",
    "            r.zero.add(j.id)\n",
    "        elif len(w) == 1:\n",
    "            r.one.add(j.id)\n",
    "        else:\n",
    "            r.multi.add(j.id)\n",
    "    print(str(len(r.one)/len(r.jfnames)*100)[:2]+\"%\")\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = t(\"1girl|solo|1boy\")-t(\"1girl&1boy\")-t(\"2boys|2girls|3boys|3girls|4boys|4girls|5boys|5girls|6+boys|6+girls|multiple_boys|multiple_girls|multiple_views|variations\")\n",
    "white = t(\"white_background|transparent_background\")\n",
    "exc0 = t('|'.join([\n",
    "    \"no_humans|arachne|pokemon_(creature)|octoling|monster_girl|isabelle_(animal_crossing)|animal_nose|animal_hug\",\n",
    "    \"robot|cyborg|mecha_musume|machinery|doll_joints|crewmate_(among_us)|kamen_rider_faiz|olimar\",\n",
    "    \"red_skin|blue_skin|purple_skin|wrinkled_skin|green_skin|two-tone_skin\",\n",
    "    \"monochrome|lineart|text_only_page|photo-referenced|3d|unconventional_media|comic\",\n",
    "    \"full_armor|weapon|chibi|cannon|mask|eyepatch\",\n",
    "]))\n",
    "exc1 = t('|'.join([\n",
    "    \"zoom_layer\",\n",
    "    \"back|ass|from_behind|from_above|bent_over|dutch_angle|standing_split\",\n",
    "    \"car|bicycle\",\n",
    "    \"translation_request\",\n",
    "    \"fox_tail\",\n",
    "    \"otter_costume\",\n",
    "    \"sonic_the_hedgehog\",\n",
    "    \"mystery_skulls\",\n",
    "    \"floating_head\",\n",
    "]))|reduce(set.__or__, fire_eggs.values())\n",
    "\n",
    "fl  = [ solo&readable_ori        ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"solo\"     ))\n",
    "fl += [ fl[-1]-exc0              ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"exc0\"     ))\n",
    "fl += [ fl[-1]&tags[\"standing\"]  ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"standing\" ))\n",
    "fl += [ fl[-1]&ge512             ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"ge512\"    ))\n",
    "fl += [ fl[-1]&ge1024            ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"ge1024\"   ))\n",
    "#fl += [ fl[-1]&tags[\"highres\"]   ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"highres\"  ))\n",
    "fl += [ fl[-1]&white             ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"white\"    ))\n",
    "fl += [ fl[-1]-tags[\"censored\"]  ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"censored\" ))\n",
    "fl += [ fl[-1]&safe              ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"safe\"     ))\n",
    "fl += [ fl[-1]&tags[\"full_body\"] ] ; print(\"{}  {:>9,}  {}\".format(len(fl)-1, len(fl[-1]), \"full_body\"))\n",
    "nofull = fl[7]-exc1                ; print(\"{}  {:>9,}  {}\".format(\"x\", len(nofull), \"nofull\"))\n",
    "nofullj = groupj(map(id2json, nofull))\n",
    "v3 = nofull&nofullj.one            ;  print(\"{}  {:>9,}  {}\".format(\"x\", len(v3), \"v3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v3_score = list(v3)\n",
    "v3_score.sort(key = lambda _id: int(ids[_id][\"score\"]), reverse=True)\n",
    "Viewer(map(id2original, v3_score), seed=-1, name=\"v3_score\", N=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_option(_id, dname, xc=0.5, yc=0.28, yw=0.235, size=512):\n",
    "    fname = id2original(_id)\n",
    "    j = load_json(id2json(_id))\n",
    "    src = dotdict()\n",
    "    dst = dotdict()\n",
    "    src.X, src.Y = imagesize.get(fname)\n",
    "    i = np.where(j.label==1)[0][0]\n",
    "    src.Xmin = src.X*j.xmin[i]\n",
    "    src.Xmax = src.X*j.xmax[i]\n",
    "    src.Ymin = src.Y*j.ymin[i]\n",
    "    src.Ymax = src.Y*j.ymax[i]\n",
    "    src.Ywid = src.Ymax-src.Ymin\n",
    "    src.Xcen = (src.Xmax+src.Xmin)/2\n",
    "    src.Ycen = (src.Ymax+src.Ymin)/2\n",
    "    dst = dotdict()\n",
    "    dst.Xcen = size*xc\n",
    "    dst.Ycen = size*yc\n",
    "    dst.Ywid = size*yw\n",
    "    z = dst.Ywid/src.Ywid\n",
    "    option = [\n",
    "        \"-background\", \"white\",\n",
    "        \"-resize\", f\"{round(100*z)}%\",\n",
    "        \"-crop\", f\"{size}x{size}+{round(z*src.Xcen-dst.Xcen)}+{round(z*src.Ycen-dst.Ycen)}!\",\n",
    "        \"-flatten\",\n",
    "        \"-strip\",\n",
    "        \"-quality\", \"100\",\n",
    "        f\"{fname}\",\n",
    "        f\"PNG24:{dname}\",\n",
    "    ]\n",
    "    return option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = list()\n",
    "for _id in tqdm(v3_score):\n",
    "    option = \" \".join(convert_option(_id, id2fname(_id, prefix=\"v3\")))\n",
    "    options.append(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dump(options, \"option_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = list()\n",
    "for fname in tqdm(list((root/\"danbooru2020/v3\").glob(\"**/*.png\"))):\n",
    "    sample.append( np.array(Image.open(fname)) )\n",
    "Image.fromarray(np.mean(sample, axis=0).astype(\"uint8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
